{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "successful-longer",
   "metadata": {},
   "source": [
    "Nosson Weissman <br>\n",
    "Professor James Topor  <br>\n",
    "AIM 5001  <br>\n",
    "March 31, 2021 \n",
    "Nosson Weissman\n",
    "# AIM 5001 Project 3 (Module 10) \n",
    "### (100 Points)\n",
    "# Data Preparation & Feature Engineering\n",
    "_________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-squad",
   "metadata": {},
   "source": [
    "When the number of explanatory variables is relatively large with respect to the number of observations contained \n",
    "within a data set, data science practitioners need to know how to effectively reduce the number of explanatory \n",
    "variables required for the intended model. Furthermore, as we’ve learned, the individual variables within a \n",
    "data set may need to be transformed prior to use within a machine learning algorithm. Additionally, we’ve \n",
    "learned that missing data values can impede the proper functioning of many machine learning algorithms. For \n",
    "this assignment your primary task is to apply data preparation and feature engineering techniques to a data \n",
    "set comprised of information related to automobile gas mileage. The data set you will be using is sourced \n",
    "from the UC Irvine machine learning archive: \n",
    "<br> https://archive.ics.uci.edu/ml/datasets/Automobile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-origin",
   "metadata": {},
   "source": [
    "## Data Loading:\n",
    "**(5 Points)** <br>  <br>\n",
    "Python code used to load the data set + assign \n",
    "meaningful names to each column within the dataset\n",
    "____________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-abuse",
   "metadata": {},
   "source": [
    "The data set is comprised of 205 observations and 26 attributes. Please refer to the UCI web page for further \n",
    "details on these variables. You are to apply your data preparation and feature engineering expertise to the \n",
    "problems listed below. But first, get started with the Assignment as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-amsterdam",
   "metadata": {},
   "source": [
    "Load the provided M10_Data.csv file to your AIM 5001 Github Repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-shower",
   "metadata": {},
   "source": [
    "Then, using a Jupyter Notebook, read the data set from your Github repository and load it into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-ethernet",
   "metadata": {},
   "source": [
    " Assign meaningful column headings to the content of the dataframe based on the \n",
    "information provided at the UCI web link provided above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-layout",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis: \n",
    "**(25 Points)** <br> <br>\n",
    "Explain + present your EDA work including any conclusions you \n",
    "draw from your.<br> This section should include any Python code used for the EDA.\n",
    "____________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-station",
   "metadata": {},
   "source": [
    "Using your Python skills, perform some basic exploratory data analysis (EDA) to ensure you understand \n",
    "the nature of each of the variables contained within the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-engineering",
   "metadata": {},
   "source": [
    "Your EDA writeup should include any \n",
    "insights you are able to derive from your statistical analysis of the attributes and the accompanying \n",
    "exploratory graphics you create (e.g., bar plots, box plots, histograms, line plots, etc.). It is up to you as \n",
    "the data science practitioner to decide how you go about your EDA, including selecting appropriate \n",
    "statistical metrics to be calculated + which types of exploratory graphics to make use of. Your goal \n",
    "should be to provide an EDA that is thorough and succinct without it being so detailed that a reader \n",
    "will lose interest in it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-defeat",
   "metadata": {},
   "source": [
    "## Data Preparation & Feature Engineering:\n",
    "**(70 Points)** <br> <br>\n",
    "Contains all Python code and explanatory commentary related to your analysis and answers for Questions 1 through 5\n",
    "____________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-premium",
   "metadata": {},
   "source": [
    "When you have completed your EDA work, use the results of that work to help you answer the following \n",
    "questions:<br>\n",
    "**1. (10 Points)** Which numeric variables contained within the data set appear to require the use of a feature scaling method for purposes of preparing them for use within a machine learning algorithm? \n",
    "Be sure to list each relevant variable and explain why you believe each variable that you’ve identified requires the use of some sort of feature scaling method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-chosen",
   "metadata": {},
   "source": [
    "**2. (15 Points)** Consider the number-of-doors and price variables: Based on your EDA work, how many \n",
    "missing data values occur within each of these attributes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-organizer",
   "metadata": {},
   "source": [
    "As we’ve learned, missing data values can \n",
    "impede the proper functioning of many machine learning algorithms. To address the missing the \n",
    "number-of-doors and price values, you have been instructed to formulate what you believe will be an effective data imputation approach for purposes of estimating reasonable proxies for the missing data \n",
    "values. Your supervisor tells you that the affected data observations MUST be retained within the data \n",
    "set, and that it would be inappropriate to use either a mean, median, or mode value for any of the \n",
    "missing values since doing so would increase the likelihood of introducing unwarranted bias within the \n",
    "data set. Describe the imputation method you would employ for each variable. Then, using your \n",
    "Python skills, apply your prescribed imputation methods to the variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-reverse",
   "metadata": {},
   "source": [
    "Be sure to include graphics \n",
    "and commentary that explain your approach as well as the results of your efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-stereo",
   "metadata": {},
   "source": [
    "**3. (15 Points)** Consider the engine-size and stroke variables: Describe the specific feature scaling method \n",
    "you would apply to each of them. Then, using Python, generate both a histogram and a boxplot for the \n",
    "original content of these two variables. Next, apply your prescribed feature scaling methods to the two \n",
    "variables and create histograms and boxplots that show the results of your feature scaling efforts. \n",
    "Compare your newly created plots against the plots you created for the original content of the \n",
    "variables. Comment on whether your feature scaling efforts improved the distribution of the data. If \n",
    "your feature scaling efforts did not improve the distribution of the data, explain why you believe your \n",
    "efforts were not effective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-remark",
   "metadata": {},
   "source": [
    "**4. (15 Points)** Consider the symboling, make, and engine-type variables:\n",
    "A) For each variable, specify whether its content is numeric/continuous, numeric/discrete, \n",
    "categorical/nominal, or categorical/ordinal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-capital",
   "metadata": {},
   "source": [
    "B) For each variable, describe the methodology you would employ for purposes of preparing its data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-matter",
   "metadata": {},
   "source": [
    "B) For each variable, describe the methodology you would employ for purposes of preparing its data values for use within a machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-reputation",
   "metadata": {},
   "source": [
    "C) Using your Python skills, apply your prescribed data preparation methodologies to the three \n",
    "variables. Be sure to show a sample of your results within you Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-aluminum",
   "metadata": {},
   "source": [
    "**5. (15 Points)** Consider the wheel-base, length, width, height, curb-weight, engine-size, compression-ratio, horsepower, peak-rpm, and city-mpg variables. Using your dimensionality reduction expertise, \n",
    "use Python to reduce the dimensionality of this group of variables to a set of new orthogonal features. \n",
    "Be sure to include appropriate commentary explaining the dimensionality reduction method you have \n",
    "elected to implement and discuss the results of your efforts. For example, you should explain how \n",
    "many orthogonal features your approach has generated as well as how much variability is explained by \n",
    "each of your new features.\n",
    "Your deliverable for this Project is your Jupyter Notebook. It should contain a combination of Python code \n",
    "cells and explanatory narratives contained within properly formatted Markdown cells. The Notebook should \n",
    "contain (at a minimum) the following sections (including the relevant Python code for each section):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
