{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "oriental-stanley",
   "metadata": {},
   "source": [
    "Atreish Ramlakhan<br> Aishwarya Singh<br> Nosson Weissman<br>\n",
    "April 13, 2021 \n",
    "AIM 5001, Prof. James Topor  <br>\n",
    "\n",
    "# AIM 5001 Module 12 \n",
    "## Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-trace",
   "metadata": {},
   "source": [
    "As we’ve learned, many organizations rely on sentiment analysis algorithms to help them gauge the opinions \n",
    "of both existing and potential customers. For example, companies such as Amazon, TripAdvisor, Booking.com, \n",
    "WalMart, and Yelp (amongst others) apply sentiment analysis algorithms to the online product/service \n",
    "reviews provided by their customers to better understand how the public perceives competing products and \n",
    "services.\n",
    "Your task for the Module 12 Assignment is to prepare a collection of text documents for use within a \n",
    "sentiment analysis algorithm. The data set you will be working with is sourced from this site: \n",
    "http://www.cs.cornell.edu/people/pabo/movie-review-data/. Specifically, you will be working with the polarity dataset \n",
    "v2.0, which is comprised of 1000 positive and 1000 negative movie reviews. Each movie review is in the form of free\u0002form text captured from web site postings. To complete this assignment you will need to make use of a fair \n",
    "amount of pre-processing techniques to prepare the content of the reviews for use within a classification \n",
    "model (e.g., strip out punctuation, stop words, “tokenize” the data, etc.).\n",
    "Get started on the Assignment as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-bloom",
   "metadata": {},
   "source": [
    "1) Download the review_polarity.tar.gz file to your local environment and decompress its contents. The \n",
    "compressed file contains two directories: neg which contains 1000 negative movie reviews; and pos\n",
    "which contains 1000 positive movie reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-gross",
   "metadata": {},
   "source": [
    "2) Load the neg and pos directories to your AIM 5001 Github Repository. You need to keep the content of \n",
    "the directories separated since the directories themselves serve as the labels for the classification of \n",
    "the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-export",
   "metadata": {},
   "source": [
    "3) Then, using a Jupyter Notebook, construct an algorithm (DO NOT USE scikit-learn COUNTVECTORIZER) \n",
    "that will read the content of each individual movie review from your new Github directories and \n",
    "convert that content into a properly labeled (i.e., POS / NEG or some appropriate proxy thereof) entry \n",
    "within a Pandas dataframe that encompasses all of the possible words contained within the 2000 \n",
    "movie reviews. When finished, the contents of your Pandas dataframe will constitute a term-document \n",
    "matrix for the movie review data. While constructing this term-document matrix within your Pandas \n",
    "dataframe, you should ensure that you remove any punctuation or stop words from the reviews. How \n",
    "you choose to manage the construction and proper labeling of the term-document matrix is up to you \n",
    "as the text mining / Python practitioner to decide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-hudson",
   "metadata": {},
   "source": [
    "4) Convert the cumulative frequency count data content of your newly created Pandas dataframe into a \n",
    "NumPy array. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-dairy",
   "metadata": {},
   "source": [
    "5) Using the NumPy array, calculate the sparsity of the term-document matrix. What percentage of the \n",
    "entries in your term-document matrix contain zeroes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-flashing",
   "metadata": {},
   "source": [
    "6) Next, using the content of the Pandas dataframe, plot the frequency distribution for the 30 words \n",
    "which occur most frequently in the positive reviews. What insights can you derive from the plot?7) Then, once again using the content of the Pandas dataframe, plot the frequency distribution for the 30 \n",
    "words which occur most frequently in the negative reviews. What insights can you derive from the \n",
    "plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-folks",
   "metadata": {},
   "source": [
    "8) Now that you have successfully constructed and properly labeled the term-document matrix entries\n",
    "for each of the 2000 individual movie reviews, randomly sample 75% of the vectors contained within \n",
    "the term-document matrix for use as a model training data subset while leaving the remaining 25% of \n",
    "the vectors for the model testing data subset. How you choose to split the data is up to you as the data \n",
    "science / Python practitioner to decide. Be sure to display samples of your training and testing subsets \n",
    "to a reader of your work. Also, tell us how many documents are contained within your training subset? \n",
    "How many documents are contained in your testing subset? How many positive and negative reviews \n",
    "are contained within each subset? Does the mix of positive and negative reviews appear to be \n",
    "relatively balanced within each of the subsets? Be sure to provide a suitable explanatory narrative in \n",
    "the form of formatted Markdown cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-israeli",
   "metadata": {},
   "source": [
    "Your Jupyter notebook deliverable should contain (at a minimum) the following sections (including the relevant Python code for each \n",
    "section):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-knight",
   "metadata": {},
   "source": [
    "1) Introduction (5 Points): Summarize the problem + explain the steps you plan to take to address the \n",
    "problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-toddler",
   "metadata": {},
   "source": [
    "2) Data Preparation (40 Points): Describe + show the steps you have taken to load + transform the \n",
    "provided data into properly labeled count vectors within a Pandas-based Term-Document matrix. This \n",
    "section should include any Python code used for Data Preparation as well as an appropriate \n",
    "explanatory narrative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-warner",
   "metadata": {},
   "source": [
    "3) Calculate Matrix Sparsity (20 Points): Describe + show the steps you have taken to transform your \n",
    "Pandas dataframe to a NumPy array. Describe + show the steps you have taken to calculate the \n",
    "sparsity of your term-document matrix. This section should include any Python code used for Data \n",
    "Preparation as well as an appropriate explanatory narrative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-runner",
   "metadata": {},
   "source": [
    "4) Frequency Distribution Plots (20 Points): Explain + present your word count frequency distribution \n",
    "plots for the positive and negative reviews. This section should include any Python code used for \n",
    "creating the plots as well as an appropriate explanatory narrative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-labor",
   "metadata": {},
   "source": [
    "5) Sentiment Analysis Model Preparation (15 Points): Explain + present the process by which you \n",
    "separated the count vectors into training and testing subsets. This section should include any Python \n",
    "code used for creating the training + testing as well as an appropriate explanatory narrative.\n",
    "Your Jupyter Notebook deliverable should be similar to that of a publication-quality / professional caliber \n",
    "document and should include clearly labeled graphics, high-quality formatting, clearly defined section and \n",
    "sub-section headers, and be free of spelling and grammar errors. Furthermore, your Pythion code should \n",
    "include succinct explanatory comments. \n",
    "Upload / submit your Jupyter Notebook within the provided M12 Assignment Canvas submission portal. Be sure to \n",
    "save your Notebook using the following nomenclature: first initial_last name_M12_assn\" (e.g., J_Smith_M12_assn). Small groups should identity all group members at the start of the Jupyter Notebook \n",
    "and each team member should submit their own copy of the team’s work within Canvas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
